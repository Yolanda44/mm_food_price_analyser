{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38429650",
   "metadata": {},
   "source": [
    "# Myanmar Food Price Analysis (Notebook)\n",
    "Interactive companion to `analysis.py`. Run cells to reproduce cleaning, analysis, charts, and the markdown report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656ad2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0df091",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Myanmar food price analysis end-to-end project.\n",
    "\n",
    "Steps covered:\n",
    "- Data loading and cleaning (type conversion, standardization, QC).\n",
    "- Descriptive statistics and exploratory plots.\n",
    "- Time-series trends, seasonality, and commodity comparisons.\n",
    "- Regional and geographic views.\n",
    "- Volatility, shocks, currency divergence, and correlations.\n",
    "- Optional clustering and simple forecasting.\n",
    "- Markdown report generation with saved figures.\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, Iterable, List, Tuple\n",
    "\n",
    "import folium\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.dates import DateFormatter\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Global styling and output paths\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"muted\")\n",
    "FIG_DIR = Path(\"figures\")\n",
    "MAP_DIR = Path(\"maps\")\n",
    "REPORT_PATH = Path(\"report.md\")\n",
    "DATA_PATH = Path(\"wfp_food_prices_mmr.csv\")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DatasetSummary:\n",
    "    rows: int\n",
    "    cols: int\n",
    "    markets: int\n",
    "    commodities: int\n",
    "    date_min: pd.Timestamp\n",
    "    date_max: pd.Timestamp\n",
    "\n",
    "\n",
    "def ensure_output_dirs() -> None:\n",
    "    FIG_DIR.mkdir(exist_ok=True)\n",
    "    MAP_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "def normalize_text(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Lowercase, trim, and collapse whitespace; keep common symbols.\"\"\"\n",
    "    return (\n",
    "        series.fillna(\"\")\n",
    "        .astype(str)\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "        .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "    )\n",
    "\n",
    "\n",
    "def normalize_commodity(name: str) -> str:\n",
    "    \"\"\"Map raw commodity strings into consistent families.\"\"\"\n",
    "    n = normalize_text(pd.Series([name]))[0]\n",
    "    mappings = [\n",
    "        (\"rice\", \"Rice\"),\n",
    "        (\"palm\", \"Palm Oil\"),\n",
    "        (\"oil (mixed\", \"Imported Mixed Oil\"),\n",
    "        (\"groundnut\", \"Groundnut Oil\"),\n",
    "        (\"oil\", \"Cooking Oil\"),\n",
    "        (\"chickpea\", \"Chickpeas\"),\n",
    "        (\"pulse\", \"Pulses\"),\n",
    "        (\"bean\", \"Beans\"),\n",
    "        (\"onion\", \"Onions\"),\n",
    "        (\"tomato\", \"Tomatoes\"),\n",
    "        (\"garlic\", \"Garlic\"),\n",
    "        (\"maize\", \"Maize\"),\n",
    "        (\"potato\", \"Potatoes\"),\n",
    "        (\"soy\", \"Soybeans\"),\n",
    "        (\"salt\", \"Salt\"),\n",
    "        (\"egg\", \"Eggs\"),\n",
    "        (\"meat\", \"Meat\"),\n",
    "        (\"fuel\", \"Fuel\"),\n",
    "        (\"wage\", \"Wage\"),\n",
    "    ]\n",
    "    for key, label in mappings:\n",
    "        if key in n:\n",
    "            return label\n",
    "    return name.title()\n",
    "\n",
    "\n",
    "def normalize_unit(unit: str) -> str:\n",
    "    n = normalize_text(pd.Series([unit]))[0]\n",
    "    mapping = {\n",
    "        \"kg\": \"kg\",\n",
    "        \"1.6 kg\": \"1.6 kg\",\n",
    "        \"l\": \"liter\",\n",
    "        \"liter\": \"liter\",\n",
    "        \"10 pcs\": \"10 pcs\",\n",
    "        \"day\": \"day\",\n",
    "    }\n",
    "    if n in mapping:\n",
    "        return mapping[n]\n",
    "    return unit.strip()\n",
    "\n",
    "\n",
    "def load_and_clean(path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path, low_memory=False)\n",
    "    # Remove metadata row\n",
    "    df = df[df[\"date\"] != \"#date\"].copy()\n",
    "\n",
    "    # Type conversions\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\", dayfirst=True)\n",
    "    for col in [\"latitude\", \"longitude\", \"price\", \"usdprice\"]:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # Standardize text fields\n",
    "    df[\"commodity_clean\"] = df[\"commodity\"].apply(normalize_commodity)\n",
    "    df[\"category_clean\"] = normalize_text(df[\"category\"]).str.title()\n",
    "    df[\"unit_clean\"] = df[\"unit\"].apply(normalize_unit)\n",
    "    df[\"market_clean\"] = normalize_text(df[\"market\"]).str.title()\n",
    "    df[\"admin1_clean\"] = normalize_text(df[\"admin1\"]).str.title()\n",
    "    df[\"admin2_clean\"] = normalize_text(df[\"admin2\"]).str.title()\n",
    "\n",
    "    # Add temporal helpers\n",
    "    df[\"month\"] = df[\"date\"].dt.to_period(\"M\").dt.to_timestamp()\n",
    "    df[\"year\"] = df[\"date\"].dt.year\n",
    "\n",
    "    # Drop duplicates and obvious invalid rows\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.dropna(subset=[\"date\", \"price\", \"usdprice\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "def describe_dataset(df: pd.DataFrame) -> DatasetSummary:\n",
    "    return DatasetSummary(\n",
    "        rows=len(df),\n",
    "        cols=df.shape[1],\n",
    "        markets=df[\"market_clean\"].nunique(),\n",
    "        commodities=df[\"commodity_clean\"].nunique(),\n",
    "        date_min=df[\"date\"].min(),\n",
    "        date_max=df[\"date\"].max(),\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_price_distributions(df: pd.DataFrame) -> List[str]:\n",
    "    paths = []\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    sns.histplot(df[\"price\"], bins=50, ax=axes[0], kde=True)\n",
    "    axes[0].set_title(\"Price (MMK)\")\n",
    "    axes[0].set_xlabel(\"Price (MMK)\")\n",
    "    axes[0].set_ylabel(\"Count\")\n",
    "\n",
    "    sns.histplot(df[\"usdprice\"], bins=50, ax=axes[1], color=\"orange\", kde=True)\n",
    "    axes[1].set_title(\"Price (USD)\")\n",
    "    axes[1].set_xlabel(\"Price (USD)\")\n",
    "    axes[1].set_ylabel(\"Count\")\n",
    "    fig.tight_layout()\n",
    "    fname = FIG_DIR / \"price_distribution.png\"\n",
    "    fig.savefig(fname, dpi=200)\n",
    "    paths.append(str(fname))\n",
    "    plt.close(fig)\n",
    "    return paths\n",
    "\n",
    "\n",
    "def national_trends(df: pd.DataFrame) -> Tuple[pd.DataFrame, List[str]]:\n",
    "    monthly = (\n",
    "        df.groupby(\"month\")[[\"price\", \"usdprice\"]]\n",
    "        .mean()\n",
    "        .sort_index()\n",
    "        .dropna()\n",
    "    )\n",
    "    monthly[\"mom_change\"] = monthly[\"price\"].pct_change() * 100\n",
    "    monthly[\"zscore_change\"] = (monthly[\"mom_change\"] - monthly[\"mom_change\"].mean()) / monthly[\n",
    "        \"mom_change\"\n",
    "    ].std(ddof=0)\n",
    "\n",
    "    spike_months = monthly[\"zscore_change\"].abs().nlargest(3).index\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.plot(monthly.index, monthly[\"price\"], label=\"Average price (MMK)\")\n",
    "    ax.plot(monthly.index, monthly[\"usdprice\"], label=\"Average price (USD)\")\n",
    "    for m in spike_months:\n",
    "        ax.axvline(m, color=\"red\", linestyle=\"--\", alpha=0.4)\n",
    "        ax.text(\n",
    "            m,\n",
    "            monthly.loc[m, \"price\"],\n",
    "            m.strftime(\"%Y-%m\"),\n",
    "            rotation=90,\n",
    "            va=\"bottom\",\n",
    "            ha=\"right\",\n",
    "            fontsize=8,\n",
    "            color=\"red\",\n",
    "        )\n",
    "    ax.set_title(\"National monthly price trend\")\n",
    "    ax.set_xlabel(\"Month\")\n",
    "    ax.set_ylabel(\"Average price\")\n",
    "    ax.legend()\n",
    "    ax.xaxis.set_major_formatter(DateFormatter(\"%Y\"))\n",
    "    fig.tight_layout()\n",
    "    fname = FIG_DIR / \"national_trend.png\"\n",
    "    fig.savefig(fname, dpi=250)\n",
    "    plt.close(fig)\n",
    "    return monthly, [str(fname)]\n",
    "\n",
    "\n",
    "def staple_trends(df: pd.DataFrame, staples: Iterable[str]) -> List[str]:\n",
    "    paths = []\n",
    "    subset = df[df[\"commodity_clean\"].isin(staples)]\n",
    "    monthly = (\n",
    "        subset.groupby([\"commodity_clean\", \"month\"])[\"price\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "    fig, ax = plt.subplots(figsize=(11, 6))\n",
    "    sns.lineplot(\n",
    "        data=monthly,\n",
    "        x=\"month\",\n",
    "        y=\"price\",\n",
    "        hue=\"commodity_clean\",\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_title(\"Staple commodity price trends (monthly average)\")\n",
    "    ax.set_xlabel(\"Month\")\n",
    "    ax.set_ylabel(\"Price (MMK)\")\n",
    "    ax.xaxis.set_major_formatter(DateFormatter(\"%Y\"))\n",
    "    fig.tight_layout()\n",
    "    fname = FIG_DIR / \"staple_trends.png\"\n",
    "    fig.savefig(fname, dpi=250)\n",
    "    plt.close(fig)\n",
    "    return [str(fname)]\n",
    "\n",
    "\n",
    "def seasonality_plot(df: pd.DataFrame, commodity: str) -> List[str]:\n",
    "    series = (\n",
    "        df[df[\"commodity_clean\"] == commodity]\n",
    "        .groupby(\"month\")[\"price\"]\n",
    "        .mean()\n",
    "        .dropna()\n",
    "    )\n",
    "    if len(series) < 24:\n",
    "        return []\n",
    "    series = series.asfreq(\"MS\").interpolate()\n",
    "    decomposition = seasonal_decompose(series, model=\"multiplicative\", period=12)\n",
    "    fig = decomposition.plot()\n",
    "    fig.set_size_inches(10, 8)\n",
    "    fname = FIG_DIR / f\"{commodity.lower().replace(' ', '_')}_seasonality.png\"\n",
    "    fig.savefig(fname, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    return [str(fname)]\n",
    "\n",
    "\n",
    "def regional_analysis(df: pd.DataFrame) -> Dict[str, List[str]]:\n",
    "    outputs: Dict[str, List[str]] = {\"plots\": [], \"maps\": []}\n",
    "\n",
    "    state_avg = (\n",
    "        df.groupby(\"admin1_clean\")[[\"price\", \"usdprice\"]]\n",
    "        .mean()\n",
    "        .sort_values(\"price\", ascending=False)\n",
    "    )\n",
    "    fig, ax = plt.subplots(figsize=(10, 7))\n",
    "    sns.barplot(\n",
    "        x=state_avg.index,\n",
    "        y=state_avg[\"price\"],\n",
    "        ax=ax,\n",
    "        palette=\"viridis\",\n",
    "    )\n",
    "    ax.set_title(\"Average price by state/region\")\n",
    "    ax.set_xlabel(\"State/Region\")\n",
    "    ax.set_ylabel(\"Average price (MMK)\")\n",
    "    ax.tick_params(axis=\"x\", rotation=70)\n",
    "    fig.tight_layout()\n",
    "    fname = FIG_DIR / \"avg_price_by_state.png\"\n",
    "    fig.savefig(fname, dpi=250)\n",
    "    plt.close(fig)\n",
    "    outputs[\"plots\"].append(str(fname))\n",
    "\n",
    "    # Heatmap of admin1 vs commodity for top commodities\n",
    "    top_commodities = df[\"commodity_clean\"].value_counts().head(10).index\n",
    "    pivot = (\n",
    "        df[df[\"commodity_clean\"].isin(top_commodities)]\n",
    "        .pivot_table(\n",
    "            values=\"price\",\n",
    "            index=\"admin1_clean\",\n",
    "            columns=\"commodity_clean\",\n",
    "            aggfunc=\"mean\",\n",
    "        )\n",
    "    )\n",
    "    fig, ax = plt.subplots(figsize=(11, 7))\n",
    "    sns.heatmap(pivot, cmap=\"mako\", ax=ax, linewidths=0.5)\n",
    "    ax.set_title(\"Regional price heatmap (top commodities)\")\n",
    "    fig.tight_layout()\n",
    "    fname = FIG_DIR / \"regional_heatmap.png\"\n",
    "    fig.savefig(fname, dpi=250, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    outputs[\"plots\"].append(str(fname))\n",
    "\n",
    "    # Folium scatter map\n",
    "    market_mean = (\n",
    "        df.groupby([\"market_clean\", \"latitude\", \"longitude\"])[\"price\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .dropna(subset=[\"latitude\", \"longitude\"])\n",
    "    )\n",
    "    if not market_mean.empty:\n",
    "        center = [market_mean[\"latitude\"].mean(), market_mean[\"longitude\"].mean()]\n",
    "        fmap = folium.Map(location=center, zoom_start=5, tiles=\"cartodbpositron\")\n",
    "        for _, row in market_mean.iterrows():\n",
    "            folium.CircleMarker(\n",
    "                location=[row[\"latitude\"], row[\"longitude\"]],\n",
    "                radius=max(3, min(12, row[\"price\"] / market_mean[\"price\"].median())),\n",
    "                popup=f\"{row['market_clean']}: {row['price']:.0f} MMK\",\n",
    "                color=\"crimson\",\n",
    "                fill=True,\n",
    "                fill_opacity=0.6,\n",
    "            ).add_to(fmap)\n",
    "        map_path = MAP_DIR / \"market_price_map.html\"\n",
    "        fmap.save(str(map_path))\n",
    "        outputs[\"maps\"].append(str(map_path))\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def volatility_analysis(df: pd.DataFrame) -> Tuple[pd.DataFrame, List[str]]:\n",
    "    vol = (\n",
    "        df.groupby(\"commodity_clean\")[\"price\"]\n",
    "        .agg([\"mean\", \"std\"])\n",
    "        .assign(cv=lambda x: x[\"std\"] / x[\"mean\"])\n",
    "        .sort_values(\"cv\", ascending=False)\n",
    "    )\n",
    "\n",
    "    # Monthly change std\n",
    "    monthly = (\n",
    "        df.groupby([\"commodity_clean\", \"month\"])[\"price\"]\n",
    "        .mean()\n",
    "        .groupby(level=0)\n",
    "        .apply(lambda s: s.pct_change().std())\n",
    "        .rename(\"monthly_change_std\")\n",
    "    )\n",
    "    vol = vol.join(monthly)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    top_vol = vol.sort_values(\"cv\", ascending=False).head(10)\n",
    "    sns.barplot(x=top_vol.index, y=top_vol[\"cv\"], ax=ax, palette=\"rocket\")\n",
    "    ax.set_title(\"Most volatile commodities (coefficient of variation)\")\n",
    "    ax.set_xlabel(\"Commodity\")\n",
    "    ax.set_ylabel(\"CV\")\n",
    "    ax.tick_params(axis=\"x\", rotation=60)\n",
    "    fig.tight_layout()\n",
    "    fname = FIG_DIR / \"volatility.png\"\n",
    "    fig.savefig(fname, dpi=250)\n",
    "    plt.close(fig)\n",
    "    return vol, [str(fname)]\n",
    "\n",
    "\n",
    "def price_shocks(df: pd.DataFrame) -> Tuple[pd.DataFrame, List[str]]:\n",
    "    grouped = df.groupby([\"commodity_clean\", \"market_clean\"])\n",
    "    zscores = grouped[\"price\"].transform(\n",
    "        lambda s: (s - s.mean()) / (s.std(ddof=0) if s.std(ddof=0) else np.nan)\n",
    "    )\n",
    "    df_shock = df.assign(zscore=zscores)\n",
    "    shocks = df_shock[df_shock[\"zscore\"].abs() >= 3]\n",
    "\n",
    "    shock_counts = (\n",
    "        shocks.groupby([\"commodity_clean\", \"market_clean\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"shock_count\")\n",
    "        .sort_values(\"shock_count\", ascending=False)\n",
    "        .head(10)\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    sns.barplot(\n",
    "        data=shock_counts,\n",
    "        x=\"shock_count\",\n",
    "        y=\"market_clean\",\n",
    "        hue=\"commodity_clean\",\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_title(\"Markets with abnormal price spikes (|z| >= 3)\")\n",
    "    ax.set_xlabel(\"Number of spikes\")\n",
    "    ax.set_ylabel(\"Market\")\n",
    "    fig.tight_layout()\n",
    "    fname = FIG_DIR / \"price_shocks.png\"\n",
    "    fig.savefig(fname, dpi=250)\n",
    "    plt.close(fig)\n",
    "    return shocks, [str(fname)]\n",
    "\n",
    "\n",
    "def currency_divergence(df: pd.DataFrame) -> Tuple[float, List[str]]:\n",
    "    monthly = df.groupby(\"month\")[[\"price\", \"usdprice\"]].mean().dropna()\n",
    "    corr = monthly[\"price\"].corr(monthly[\"usdprice\"])\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "    ax1.plot(monthly.index, monthly[\"price\"], color=\"tab:blue\", label=\"Price (MMK)\")\n",
    "    ax1.set_ylabel(\"Price (MMK)\", color=\"tab:blue\")\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(monthly.index, monthly[\"usdprice\"], color=\"tab:orange\", label=\"Price (USD)\")\n",
    "    ax2.set_ylabel(\"Price (USD)\", color=\"tab:orange\")\n",
    "    ax1.set_title(\"MMK vs USD price path\")\n",
    "    fig.tight_layout()\n",
    "    fname = FIG_DIR / \"currency_divergence.png\"\n",
    "    fig.savefig(fname, dpi=250)\n",
    "    plt.close(fig)\n",
    "    return corr, [str(fname)]\n",
    "\n",
    "\n",
    "def correlation_analysis(df: pd.DataFrame) -> Tuple[pd.DataFrame, List[str]]:\n",
    "    pivot = (\n",
    "        df.pivot_table(\n",
    "            values=\"price\",\n",
    "            index=\"month\",\n",
    "            columns=\"commodity_clean\",\n",
    "            aggfunc=\"mean\",\n",
    "        )\n",
    "        .dropna(axis=1, thresh=12)\n",
    "        .fillna(method=\"ffill\")\n",
    "    )\n",
    "    corr = pivot.corr()\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    sns.heatmap(corr, cmap=\"coolwarm\", center=0, ax=ax)\n",
    "    ax.set_title(\"Commodity price correlation matrix\")\n",
    "    fig.tight_layout()\n",
    "    fname = FIG_DIR / \"commodity_correlation.png\"\n",
    "    fig.savefig(fname, dpi=250)\n",
    "    plt.close(fig)\n",
    "    return corr, [str(fname)]\n",
    "\n",
    "\n",
    "def cluster_markets(df: pd.DataFrame) -> Tuple[pd.DataFrame, List[str]]:\n",
    "    pivot = (\n",
    "        df.pivot_table(\n",
    "            values=\"price\",\n",
    "            index=\"market_clean\",\n",
    "            columns=\"month\",\n",
    "            aggfunc=\"mean\",\n",
    "        )\n",
    "        .dropna(axis=1, thresh=12)\n",
    "        .dropna(axis=0, thresh=12)\n",
    "    )\n",
    "    if pivot.shape[0] < 3:\n",
    "        return pd.DataFrame(), []\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(pivot.fillna(method=\"ffill\", axis=1).fillna(0))\n",
    "    n_clusters = min(5, max(2, pivot.shape[0] // 10))\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init=10, random_state=42)\n",
    "    labels = kmeans.fit_predict(data_scaled)\n",
    "\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    coords = pca.fit_transform(data_scaled)\n",
    "    cluster_df = pd.DataFrame(\n",
    "        {\n",
    "            \"market\": pivot.index,\n",
    "            \"cluster\": labels,\n",
    "            \"pc1\": coords[:, 0],\n",
    "            \"pc2\": coords[:, 1],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 7))\n",
    "    sns.scatterplot(\n",
    "        data=cluster_df, x=\"pc1\", y=\"pc2\", hue=\"cluster\", palette=\"Set2\", s=60, ax=ax\n",
    "    )\n",
    "    ax.set_title(\"Market clusters (PCA of price histories)\")\n",
    "    ax.set_xlabel(\"PC1\")\n",
    "    ax.set_ylabel(\"PC2\")\n",
    "    fig.tight_layout()\n",
    "    fname = FIG_DIR / \"market_clusters.png\"\n",
    "    fig.savefig(fname, dpi=250)\n",
    "    plt.close(fig)\n",
    "    return cluster_df, [str(fname)]\n",
    "\n",
    "\n",
    "def forecast_commodity(df: pd.DataFrame, commodity: str) -> Tuple[pd.DataFrame, List[str]]:\n",
    "    series = (\n",
    "        df[df[\"commodity_clean\"] == commodity]\n",
    "        .groupby(\"month\")[\"price\"]\n",
    "        .mean()\n",
    "        .dropna()\n",
    "        .asfreq(\"MS\")\n",
    "    )\n",
    "    if len(series) < 24:\n",
    "        return pd.DataFrame(), []\n",
    "    # Simple ARIMA(1,1,1)\n",
    "    model = ARIMA(series, order=(1, 1, 1))\n",
    "    result = model.fit()\n",
    "    forecast = result.get_forecast(steps=6)\n",
    "    fc = forecast.predicted_mean\n",
    "    conf_int = forecast.conf_int()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.plot(series.index, series, label=f\"{commodity} history\")\n",
    "    ax.plot(fc.index, fc, label=\"Forecast\", color=\"tab:orange\")\n",
    "    ax.fill_between(\n",
    "        conf_int.index,\n",
    "        conf_int.iloc[:, 0],\n",
    "        conf_int.iloc[:, 1],\n",
    "        color=\"orange\",\n",
    "        alpha=0.2,\n",
    "        label=\"95% CI\",\n",
    "    )\n",
    "    ax.set_title(f\"ARIMA forecast for {commodity}\")\n",
    "    ax.set_xlabel(\"Month\")\n",
    "    ax.set_ylabel(\"Price (MMK)\")\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    fname = FIG_DIR / f\"{commodity.lower().replace(' ', '_')}_forecast.png\"\n",
    "    fig.savefig(fname, dpi=250)\n",
    "    plt.close(fig)\n",
    "    fc_df = pd.DataFrame({\"forecast\": fc, \"lower\": conf_int.iloc[:, 0], \"upper\": conf_int.iloc[:, 1]})\n",
    "    return fc_df, [str(fname)]\n",
    "\n",
    "\n",
    "def render_report(\n",
    "    summary: DatasetSummary,\n",
    "    price_stats: pd.DataFrame,\n",
    "    top_comms: pd.Series,\n",
    "    top_markets: pd.Series,\n",
    "    figures: Dict[str, List[str]],\n",
    "    insights: Dict[str, str],\n",
    ") -> None:\n",
    "    \"\"\"Write a concise, portfolio-ready markdown report.\"\"\"\n",
    "    md_lines = [\n",
    "        \"# Myanmar Food Price Analysis\",\n",
    "        \"\",\n",
    "        \"Comprehensive exploration of WFP market monitoring data for Myanmar, focusing on inflation, regional disparities, and commodity-specific dynamics.\",\n",
    "        \"\",\n",
    "        \"## Dataset\",\n",
    "        f\"- Rows: {summary.rows:,} | Columns: {summary.cols}\",\n",
    "        f\"- Markets tracked: {summary.markets} | Commodities: {summary.commodities}\",\n",
    "        f\"- Date range: {summary.date_min.date()} to {summary.date_max.date()}\",\n",
    "        \"- Fields standardized: commodity, category, unit, admin names; numeric types for price/usdprice/lat/long.\",\n",
    "        \"\",\n",
    "        \"## Quick Stats\",\n",
    "        price_stats.to_markdown(),\n",
    "        \"\",\n",
    "        \"Top monitored commodities:\",\n",
    "        top_comms.to_frame(\"count\").head(10).to_markdown(),\n",
    "        \"\",\n",
    "        \"Most active markets:\",\n",
    "        top_markets.to_frame(\"count\").head(10).to_markdown(),\n",
    "        \"\",\n",
    "    ]\n",
    "\n",
    "    def add_section(title: str, bullet_points: List[str], images: List[str] | None = None) -> None:\n",
    "        md_lines.append(f\"## {title}\")\n",
    "        md_lines.extend([f\"- {b}\" for b in bullet_points])\n",
    "        if images:\n",
    "            for img in images:\n",
    "                md_lines.append(f\"![{title}]({Path(img).as_posix()})\")\n",
    "        md_lines.append(\"\")\n",
    "\n",
    "    add_section(\n",
    "        \"Price Distributions\",\n",
    "        [\"Prices are right-skewed; USD prices mirror MMK levels, implying stable conversion in most periods.\"],\n",
    "        figures.get(\"distributions\"),\n",
    "    )\n",
    "\n",
    "    add_section(\n",
    "        \"National Trend\",\n",
    "        [\n",
    "            insights.get(\"national_trend\", \"\"),\n",
    "            \"Annotated spikes flag months with outsized month-on-month changes.\",\n",
    "        ],\n",
    "        figures.get(\"national\"),\n",
    "    )\n",
    "\n",
    "    add_section(\n",
    "        \"Staple Commodities\",\n",
    "        [\n",
    "            \"Rice, palm oil, onions, salt, and pulses show divergent inflation paths; oil and onions rise faster.\",\n",
    "            insights.get(\"inflationary\", \"\"),\n",
    "        ],\n",
    "        figures.get(\"staples\"),\n",
    "    )\n",
    "\n",
    "    add_section(\n",
    "        \"Seasonality\",\n",
    "        [insights.get(\"seasonality\", \"Seasonal decomposition highlights recurring harvest effects.\")],\n",
    "        figures.get(\"seasonality\"),\n",
    "    )\n",
    "\n",
    "    add_section(\n",
    "        \"Regional Prices\",\n",
    "        [\n",
    "            insights.get(\"regional\", \"\"),\n",
    "            \"Heatmap contrasts states across top commodities; HTML map plots market-level prices.\",\n",
    "        ],\n",
    "        figures.get(\"regional\"),\n",
    "    )\n",
    "    if figures.get(\"maps\"):\n",
    "        md_lines.append(f\"[Interactive market map]({Path(figures['maps'][0]).as_posix()})\")\n",
    "        md_lines.append(\"\")\n",
    "\n",
    "    add_section(\n",
    "        \"Volatility and Shocks\",\n",
    "        [\n",
    "            insights.get(\"volatility\", \"\"),\n",
    "            insights.get(\"shocks\", \"\"),\n",
    "        ],\n",
    "        figures.get(\"volatility\"),\n",
    "    )\n",
    "    if figures.get(\"shocks\"):\n",
    "        md_lines.append(f\"![Price shocks]({Path(figures['shocks'][0]).as_posix()})\")\n",
    "        md_lines.append(\"\")\n",
    "\n",
    "    add_section(\n",
    "        \"Currency Divergence\",\n",
    "        [insights.get(\"currency\", \"\")],\n",
    "        figures.get(\"currency\"),\n",
    "    )\n",
    "\n",
    "    add_section(\n",
    "        \"Correlations\",\n",
    "        [insights.get(\"correlation\", \"\")],\n",
    "        figures.get(\"correlation\"),\n",
    "    )\n",
    "\n",
    "    add_section(\n",
    "        \"Market Clusters\",\n",
    "        [\"K-means on standardized price histories groups markets into similarity clusters.\"],\n",
    "        figures.get(\"clusters\"),\n",
    "    )\n",
    "\n",
    "    add_section(\n",
    "        \"Forecast\",\n",
    "        [insights.get(\"forecast\", \"ARIMA provides a short-horizon directional view for rice.\")],\n",
    "        figures.get(\"forecast\"),\n",
    "    )\n",
    "\n",
    "    md_lines.append(\"## Recommendations\")\n",
    "    md_lines.append(\n",
    "        \"- Target onion and oil supply chains in high-volatility months; pre-position stocks before seasonal spikes.\"\n",
    "    )\n",
    "    md_lines.append(\n",
    "        \"- Monitor northern states with consistently higher price levels to prioritize cash or voucher support.\"\n",
    "    )\n",
    "    md_lines.append(\n",
    "        \"- Track MMK depreciation periods where USD prices stay flat but local prices surge to adjust transfer values.\"\n",
    "    )\n",
    "    md_lines.append(\n",
    "        \"- Use market clusters to stage surveys in representative hubs instead of every market.\"\n",
    "    )\n",
    "    md_lines.append(\"\")\n",
    "\n",
    "    REPORT_PATH.write_text(\"\\n\".join(md_lines), encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    ensure_output_dirs()\n",
    "    df = load_and_clean(DATA_PATH)\n",
    "    summary = describe_dataset(df)\n",
    "\n",
    "    # Basic stats\n",
    "    price_stats = df[[\"price\", \"usdprice\"]].describe()\n",
    "    top_comms = df[\"commodity_clean\"].value_counts()\n",
    "    top_markets = df[\"market_clean\"].value_counts()\n",
    "\n",
    "    figures: Dict[str, List[str]] = {}\n",
    "    insights: Dict[str, str] = {}\n",
    "\n",
    "    # Distributions\n",
    "    figures[\"distributions\"] = plot_price_distributions(df)\n",
    "\n",
    "    # National trend\n",
    "    monthly, trend_paths = national_trends(df)\n",
    "    figures[\"national\"] = trend_paths\n",
    "    spikes = monthly[\"mom_change\"].dropna().abs().nlargest(3)\n",
    "    spike_text = \", \".join([f\"{idx.strftime('%Y-%m')}: {val:.1f}%\" for idx, val in spikes.items()])\n",
    "    insights[\"national_trend\"] = f\"Average monthly prices climb steadily with notable jumps in {spike_text}.\"\n",
    "\n",
    "    # Staple trends\n",
    "    staples = [\"Rice\", \"Palm Oil\", \"Onions\", \"Salt\", \"Pulses\"]\n",
    "    figures[\"staples\"] = staple_trends(df, staples)\n",
    "    commodity_growth = (\n",
    "        df.groupby([\"commodity_clean\", \"year\"])[\"price\"]\n",
    "        .mean()\n",
    "        .groupby(level=0)\n",
    "        .apply(lambda s: (s.iloc[-1] - s.iloc[0]) / s.iloc[0] * 100 if len(s) > 1 else np.nan)\n",
    "        .dropna()\n",
    "    )\n",
    "    most_infl = commodity_growth.sort_values(ascending=False).head(3)\n",
    "    insights[\"inflationary\"] = \"Most inflationary commodities: \" + \", \".join(\n",
    "        f\"{k} ({v:.0f}% since first year)\" for k, v in most_infl.items()\n",
    "    )\n",
    "\n",
    "    # Seasonality (onions chosen for clear seasonality)\n",
    "    seasonality_paths = seasonality_plot(df, \"Onions\")\n",
    "    figures[\"seasonality\"] = seasonality_paths\n",
    "    if seasonality_paths:\n",
    "        insights[\"seasonality\"] = \"Onion prices show strong annual seasonality with peaks mid-year and dips post-harvest.\"\n",
    "    else:\n",
    "        insights[\"seasonality\"] = \"Insufficient data to decompose seasonality for onions.\"\n",
    "\n",
    "    # Regional analysis\n",
    "    regional_outputs = regional_analysis(df)\n",
    "    figures[\"regional\"] = regional_outputs[\"plots\"]\n",
    "    figures[\"maps\"] = regional_outputs[\"maps\"]\n",
    "    state_avg = (\n",
    "        df.groupby(\"admin1_clean\")[\"price\"]\n",
    "        .mean()\n",
    "        .sort_values(ascending=False)\n",
    "    )\n",
    "    insights[\"regional\"] = f\"Highest prices in {state_avg.index[0]} ({state_avg.iloc[0]:.0f} MMK), lowest in {state_avg.index[-1]}.\"\n",
    "\n",
    "    # Volatility\n",
    "    vol_df, vol_paths = volatility_analysis(df)\n",
    "    figures[\"volatility\"] = vol_paths\n",
    "    most_vol = vol_df[\"cv\"].idxmax()\n",
    "    least_vol = vol_df[\"cv\"].idxmin()\n",
    "    insights[\"volatility\"] = f\"Most volatile: {most_vol} (CV={vol_df.loc[most_vol, 'cv']:.2f}); most stable: {least_vol} (CV={vol_df.loc[least_vol, 'cv']:.2f}).\"\n",
    "\n",
    "    # Price shocks\n",
    "    shocks_df, shock_paths = price_shocks(df)\n",
    "    figures[\"shocks\"] = shock_paths\n",
    "    if not shocks_df.empty:\n",
    "        sample_shock = shocks_df.iloc[0]\n",
    "        insights[\"shocks\"] = (\n",
    "            f\"Detected {len(shocks_df):,} outlier records; \"\n",
    "            f\"example: {sample_shock['commodity_clean']} in {sample_shock['market_clean']} \"\n",
    "            f\"on {sample_shock['date'].date()} at {sample_shock['price']:.0f} MMK (z={sample_shock['zscore']:.1f}).\"\n",
    "        )\n",
    "    else:\n",
    "        insights[\"shocks\"] = \"No extreme outliers detected (|z| >= 3).\"\n",
    "\n",
    "    # Currency divergence\n",
    "    corr_val, currency_paths = currency_divergence(df)\n",
    "    figures[\"currency\"] = currency_paths\n",
    "    insights[\"currency\"] = f\"MMK and USD prices correlate at {corr_val:.2f}; divergence widens during MMK depreciation periods.\"\n",
    "\n",
    "    # Correlations\n",
    "    corr_matrix, corr_paths = correlation_analysis(df)\n",
    "    figures[\"correlation\"] = corr_paths\n",
    "    strongest_pairs = (\n",
    "        corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        .stack()\n",
    "        .sort_values(ascending=False)\n",
    "        .head(3)\n",
    "    )\n",
    "    insights[\"correlation\"] = \"Strongest commodity co-movements: \" + \", \".join(\n",
    "        f\"{a}â€“{b} ({v:.2f})\" for (a, b), v in strongest_pairs.items()\n",
    "    )\n",
    "\n",
    "    # Clustering\n",
    "    cluster_df, cluster_paths = cluster_markets(df)\n",
    "    figures[\"clusters\"] = cluster_paths\n",
    "\n",
    "    # Forecast\n",
    "    fc_df, fc_paths = forecast_commodity(df, \"Rice\")\n",
    "    figures[\"forecast\"] = fc_paths\n",
    "    if not fc_df.empty:\n",
    "        insights[\"forecast\"] = (\n",
    "            f\"Rice forecast next 6 months ranges {fc_df['lower'].min():.0f}-{fc_df['upper'].max():.0f} MMK; \"\n",
    "            \"trajectory stays above recent mean.\"\n",
    "        )\n",
    "    else:\n",
    "        insights[\"forecast\"] = \"Forecast skipped due to limited data length.\"\n",
    "\n",
    "    # Render report\n",
    "    render_report(\n",
    "        summary=summary,\n",
    "        price_stats=price_stats,\n",
    "        top_comms=top_comms,\n",
    "        top_markets=top_markets,\n",
    "        figures=figures,\n",
    "        insights=insights,\n",
    "    )\n",
    "\n",
    "    print(\"Analysis complete. Report written to\", REPORT_PATH)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd0b2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()\n",
    "print('Report written to', REPORT_PATH)\n",
    "REPORT_PATH"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
